[
  {
    "objectID": "index.html#scan-this",
    "href": "index.html#scan-this",
    "title": "Reproducible Research in Practice",
    "section": "Scan This",
    "text": "Scan This\n\n\n    \nns-rse.github.io/reproducible_research_example"
  },
  {
    "objectID": "index.html#who-am-iwhat-do-i-do",
    "href": "index.html#who-am-iwhat-do-i-do",
    "title": "Reproducible Research in Practice",
    "section": "Who Am I/What Do I Do?",
    "text": "Who Am I/What Do I Do?\n\n\n\nBackground in evolutionary and statistical genetics.\nGenetic Statistician\nMedical Statistician\nData Scientist\n🎉 Research Software Engineer 🎉\n\n\n\nLinux, R, Python, Bash\nLiterate Programming\nReproducible Research\nOpen Research\nFree Open Source Software\n\n\n\n\nBefore we get into the details I thought it might be useful to explain who am I am and why I’m here to talk to you today.\nI started my academic career studying Zoology and Genetics at Undergraduate then moved onto a Masters in Genetic Epidemiology, both here at the University of Sheffield quite a few years ago. After graduating I spent about eight or nine years as a Genetic Statistician trying to work out what genes are involved in complex diseases at various Universities, Manchester, Western Australia and then returning to Sheffield. I then shifted careers to work as a Medical Statistician for about nine years followed by four years in industry as a Data Scientist where I didn’t actually do much data science but did learn a lot about software development which is how I’ve ended up back at the University of Sheffield as a Research Software Engineer.\nA common theme from my Masters on-wards is that I have used computers to write programmes and analyse data. I’ve taught myself Linux system administration and from a rudimentary training on Fortran, C and Stata have gone on to learn Bash, R and Python as well as a few other bits and pieces of different languages.\nVery early on in my career I developed an interest in literate programming and reproducible research which is why Aneta has invited me her today to talk to you and I’ll expand on these topics and show you some work I’m currently engaged in and how I undertake it in a reproducible manner.\nReproducible Research is one of the foundational aspects of Open Research as by ensuring our work is reproducible and open to review it improves confidence in its accuracy and reliability."
  },
  {
    "objectID": "index.html#reproducible-research",
    "href": "index.html#reproducible-research",
    "title": "Reproducible Research in Practice",
    "section": "Reproducible Research",
    "text": "Reproducible Research\n\nReproducibility is fundamental to the scientific method.\nTraditionally hand-written notebooks with methods shared in publications.\nModern equivalent is code…\n\nSoftware\nStatistical scripts\n\nData cleaning\nAnalysis, graphs & tables\nNumbers and statistics"
  },
  {
    "objectID": "index.html#literate-programming---origins",
    "href": "index.html#literate-programming---origins",
    "title": "Reproducible Research in Practice",
    "section": "Literate Programming - Origins",
    "text": "Literate Programming - Origins\n\n\n\na computer program is given as an explanation of how it works in a natural language, such as English, interspersed (embedded) with snippets of macros and traditional source code, from which compilable source code can be generated.1\n\n\n\n\n\nLiterate Programming - Donald Knuth\n\n\n\n\n\nRMarkdown and other languages like it such as the newer Quarto and Emacs’ Org-mode are literate programming languages which may be an unfamiliar term so I’ve borrowed the definition from Wikipedia.\nThe idea was originally proposed and developed the computer scientist Donald Knuth, and he literally wrote the book on it.\n\nWikipedia - Literate programming"
  },
  {
    "objectID": "index.html#literate-programming---better-programmes",
    "href": "index.html#literate-programming---better-programmes",
    "title": "Reproducible Research in Practice",
    "section": "Literate Programming - Better Programmes",
    "text": "Literate Programming - Better Programmes\n\n\n\nMy programs are not only explained better than ever before; they also are better programs, because the new methodology encourages me to do a better job.1\n\n\n\n\n\nLiterate Programming - Donald Knuth\n\n\n\n\n\nWhilst originating in computer science the principle has seen widespread adoption in research and data science because it encourages reproducible research and facilitates open access to research.\nAlso, as Knuth found when he adopted the practice it improved the quality of the programmes he wrote, and I’ve found the same is true when writing documents myself since adopting the practice over 20 years ago.\n\nKnuth (1984)"
  },
  {
    "objectID": "index.html#whats-involved",
    "href": "index.html#whats-involved",
    "title": "Reproducible Research in Practice",
    "section": "What’s Involved?",
    "text": "What’s Involved?\n\nLogical, ordered directory structure.\nScripts/code.\nVersion control of code.\nReproducible environment (R packages using renv).\n\n\nIt can seem overwhelming learning a new paradigm or framework for undertaking work and I’ve often found that people want to get on and do the work rather than take a step back and assess how they are going about it but its well worth taking the time out to review and assess your working practices and see how they can be improved.\nI’m going to walk you through a project that I’ve been working on that is looking to improve the prediction of Thyroid Cancer. Its not my own work, its the topic for a PhD for a clinicial Dr Ovie Edafe who is a specialist in neck cancers and related surgery.\nThere are four broad areas that I’ll cover that hopefully align with the content you have already covered and will be covering in the coming weeks.\nThe first step is having an organised structure to your directories having data organised in a consistent and structured manner makes it considerably easier to work with.\nYou then need to write code or scripts, which are still code, that defines the steps you undertake in cleaning and tidying your data and getting it ready for analysis before another series of scripts are used to run the analysis.\nAll of the code that is written should be version controlled which allos you to track the history of the code and see what changes have been made over time. If a mistake is made it is possible to revert back to a previous state where things did work. Version control and tools such as Git and GitHub make it much easier to collaborate with others on research too.\nOne final step is having a reproducible environment under which your work is undertaken. This means the specific versions of packages that you have used for analysis should be recorded and used again in the future. In R this can be done via the renv package. Its not without problems but the situation today is far better than it used to be."
  },
  {
    "objectID": "index.html#directory-structure",
    "href": "index.html#directory-structure",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure",
    "text": "Directory Structure\n\nImportant to keep a copy of the raw data as received.\nData always needs cleaning.\n~80% of data analysis is data cleaning/wrangling data!\nAlways keep a record of changes you make to the data.\nSeparate directories for different data types and script/markdown files.\n\n\nWhen undertaking research its imperative to keep a copy of the raw data as received. This might be data from sensors that have captured data and if you work with this sort of data then its likely to be fairly well structured, but can also be the results of surveys that have been captured and stored in databases and then exported for you to work with. Depending on how well the data capture was setup you will almost invariably have to clean your data, in my experience about 80% of data analysis is cleaning the data and wrangling it such as deriving variables like age from date of birth, and on that note if you ever do want to analyse age as a variable try and capture date of birth as you can easily derive the age in years or categorise it into bins, but if you only ask people to say what age band they are in you can’t go back the other way. Common errors in data cleaning are having string characters in variables that are meant to be numeric, or having categorical variables where people haven’t entered the correct field and so you have to then work out how to tidy this which I’ll come on to.\nThe key thin is that its important to keep a record of the changes you make and these will be in R scripts or Markdown/Quarto files. And it therefore makes sense to separate your data from your scripts."
  },
  {
    "objectID": "index.html#directory-structure---thyroid-cancer-prediction",
    "href": "index.html#directory-structure---thyroid-cancer-prediction",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - Thyroid Cancer Prediction",
    "text": "Directory Structure - Thyroid Cancer Prediction\n\n\n❱ tree -d -L 2\n[4.0K Mar 19 12:36]  .\n├── [4.0K Nov 22 14:57]  ./data\n│   ├── [4.0K Jan  9 13:32]  ./data/csv\n│   └── [4.0K Feb 29 17:27]  ./data/r\n├── [4.0K Mar 14 17:36]  ./docs\n│   ├── [   7 Jan  5 14:45]  ./docs/data -&gt; ../data\n│   ├── [4.0K Feb 29 15:38]  ./docs/modelling_cache\n│   ├── [4.0K Mar 14 17:21]  ./docs/modelling_files\n│   ├── [   4 Jan  5 14:44]  ./docs/r -&gt; ../r\n│   └── [4.0K Mar 14 17:21]  ./docs/_site\n├── [4.0K Oct 19 11:40]  ./inst\n├── [4.0K Nov 16 10:54]  ./log\n├── [4.0K Oct 19 11:24]  ./node_modules\n├── [4.0K Oct 19 12:39]  ./pages\n├── [4.0K Oct 12 10:43]  ./papers\n├── [4.0K Nov  9 11:44]  ./quarto\n│   └── [4.0K Oct 19 13:12]  ./quarto/_site\n├── [4.0K Mar 14 16:59]  ./r\n├── [4.0K Mar 14 17:28]  ./renv\n│   ├── [4.0K Nov 16 10:57]  ./renv/library\n│   └── [4.0K Feb 29 14:28]  ./renv/staging\n├── [4.0K Jan 31 11:00]  ./_site\n│   ├── [4.0K Dec 19 16:36]  ./_site/data_files\n│   ├── [4.0K Feb 15 15:15]  ./_site/docs\n│   ├── [4.0K Dec 19 16:36]  ./_site/modelling_files\n│   └── [4.0K Jan 25 17:22]  ./_site/site_libs\n└── [4.0K Feb  1 17:47]  ./tmp\n\n29 directories\n\nKey top-level directories\n\ndata/ - holds data.\ndocs/ - my Quarto files.\nr/ - my R-scripts.\n\n\n\n\nHere is an example of the directory structure of one of the repositories I have setup for this work.\nThe output only shows the nesting two directory levels deep, but you can see that at the top level I have a number of directories, not all of them are relevant, but the key ones are listed on the right, there is the data/ directory which will hold all of the data, there are two sub-directories csv for raw CSV files and r which holds cleaned data in R’s byte format which speeds up loading and preserves all the labelling and categorical variables.\nThe docs/ directory contains my Quarto source files that I write, both Quarto and RMarkdown will make a bunch of other directories when they are rendering your pages which are some of those listed such as _site but you don’t need to worry about those.\nThe final key directory that I have is r/ which holds the R scripts that I write."
  },
  {
    "objectID": "index.html#directory-structure---data",
    "href": "index.html#directory-structure---data",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - data/",
    "text": "Directory Structure - data/\n\n\n❱ tree data\n[4.0K Nov 22 14:57]  data\n├── [4.0K Jan  9 13:32]  data/csv\n│   ├── [ 20K Jan  9 13:31]  data/csv/sheffield_thyroid_nodule.csv\n│   └── [393K Nov  2 11:08]  data/csv/Thy3000_DATA_LABELS_Raw.csv\n└── [4.0K Feb 29 17:27]  data/r\n    ├── [ 30K Mar 14 11:12]  data/r/clean.rds\n    ├── [136K Feb 29 17:56]  data/r/elastic_net.RData\n    ├── [136K Feb 29 17:56]  data/r/lasso.RData\n    ├── [129K Feb 29 17:56]  data/r/rf.RData\n    ├── [137K Feb 29 17:58]  data/r/svm.RData\n    └── [ 14K Feb 29 17:56]  data/r/xgboost.RData\n\n3 directories, 9 files\n\n\n\n\ndata/csv/*.csv - CSV files\ndata/r/*.rds - R files\ndata/r/*.RData - R files\n\n\n\n\nThe data/csv directory holds the raw data and there are two files the raw data sheffield_thyroid_nodule.csv and the data dictionary Thy3000_DATA_LABELS_Raw.csv.\nThe data/r directory holds the cleaned data in clean.rds and the results of fitting various different types of models to the data in the .RData files."
  },
  {
    "objectID": "index.html#directory-structure---docs",
    "href": "index.html#directory-structure---docs",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - docs/",
    "text": "Directory Structure - docs/\n❱ l docs | grep -v \"~\"\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 17:36:04 2024 .\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 28 16:35:45 2024 ..\n.rw-r--r-- neil neil  10 B  Thu Feb 15 15:16:48 2024 .gitignore\n.rw-r--r-- neil neil  12 KB Thu Jan 25 15:35:49 2024 .modelling.qmd\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 17:15:43 2024 .quarto\n.rw-r--r-- neil neil 483 B  Thu Mar 14 16:59:28 2024 _quarto.yml\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 17:21:20 2024 _site\n.rw-r--r-- neil neil 408 B  Thu Mar 14 16:57:10 2024 about.qmd\n.rw-r--r-- neil neil 1.2 KB Thu Mar 14 16:57:10 2024 citations.qmd\nlrwxrwxrwx neil neil   7 B  Fri Jan  5 14:45:10 2024 data ⇒ ../data\n.rw-r--r-- neil neil  33 KB Thu Mar 14 16:57:10 2024 data.qmd\n.rw-r--r-- neil neil 363 B  Thu Mar 14 16:57:10 2024 index.qmd\n.rw-r--r-- neil neil 569 B  Thu Mar 14 16:57:10 2024 links.qmd\n.rw-r--r-- neil neil 2.0 KB Thu Mar 14 16:57:10 2024 literature.qmd\n.rw-r--r-- neil neil  32 KB Thu Mar 14 17:36:04 2024 modelling.qmd\ndrwxr-xr-x neil neil 4.0 KB Thu Feb 29 15:38:53 2024 modelling_cache\n.rw-r--r-- neil neil 3.5 KB Thu Mar 14 17:31:46 2024 modelling_elastic_net.qmd\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 17:21:18 2024 modelling_files\n.rw-r--r-- neil neil 5.4 KB Thu Mar 14 17:31:46 2024 modelling_lasso.qmd\n.rw-r--r-- neil neil 3.6 KB Thu Mar 14 17:31:46 2024 modelling_random_forest.qmd\n.rw-r--r-- neil neil 7.0 KB Thu Mar 14 17:31:46 2024 modelling_tidymodel.qmd\nlrwxrwxrwx neil neil   4 B  Fri Jan  5 14:44:09 2024 r ⇒ ../r\n.rw-r--r-- neil neil  18 KB Thu Mar 14 16:57:10 2024 references.bib\n.rw-r--r-- neil neil 2.7 KB Thu Mar 14 16:57:10 2024 reproducibility.qmd\n.rw-r--r-- neil neil  17 B  Thu Mar 14 16:59:28 2024 styles.css\n\nThe docs/ directory holds my Quarto files which all end in .qmd. I don’t like having large files to navigate so split my code and papers into a number of smaller files that do specific things and include these from the master document which is index.qmd. There is a references.bib file which contains citations so we can include citations easily. The _quarto.yml files is a key file which defines how the Quarto project is setup and rendered but I won’t cover that in detail here."
  },
  {
    "objectID": "index.html#directory-structure---r",
    "href": "index.html#directory-structure---r",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - r/",
    "text": "Directory Structure - r/\n❱ l r | grep -v \"~\"\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 16:59:28 2024 .\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 28 16:35:45 2024 ..\n.rw-r--r-- neil neil  28 KB Thu Mar 14 16:56:18 2024 clean.R\n.rw-r--r-- neil neil 684 B  Thu Mar 14 16:59:28 2024 master.R\n.rw-r--r-- neil neil  15 KB Thu Feb 29 14:40:13 2024 modelling.R\n.rw-r--r-- neil neil 2.6 KB Thu Mar 14 16:59:28 2024 simulate_data.R\n.rw-r--r-- neil neil 233 B  Thu Jan 25 17:02:10 2024 summary.R\n.rw-r--r-- neil neil 2.9 KB Thu Mar 14 16:57:10 2024 tidymodel.R\n\nThe r/ directory holds my R scripts, the key one is master.R which holds the main commands that setup the R environment, load libraries and set relative directories. The clean.R file does what it says on the tin, it cleans the raw data and saves it in R format. There are then scripts for modelling and simulating data.\nNow that we’ve covered how I organise my data we can start looking at some code, but before I move on are there any questions about this aspect?"
  },
  {
    "objectID": "index.html#scriptscode---master.r",
    "href": "index.html#scriptscode---master.r",
    "title": "Reproducible Research in Practice",
    "section": "Scripts/Code - master.R",
    "text": "Scripts/Code - master.R\n## Filename    : master.R\n## Description : Master file that controls running of all subsequent scripts.\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(Hmisc)\nlibrary(lubridate)\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(vip)\n\n## Set directories based on current location\nbase_dir &lt;- getwd()\ndata_dir &lt;- paste(base_dir, \"data\", sep = \"/\")\ncsv_dir &lt;- paste(data_dir, \"csv\", sep = \"/\")\nr_dir &lt;- paste(data_dir, \"r\", sep = \"/\")\nr_scripts &lt;- paste(base_dir, \"r\", sep = \"/\")\n\n## Clean the data\nsource(paste(r_scripts, \"clean.R\", sep = \"/\"))\n\n\n## Simulate data\nsource(paste(r_scripts, \"simulate_data.R\", sep = \"/\"))\n\n## Run Statistical models\nsource(paste(r_scripts, \"tidymodel.R\", sep = \"/\"))\n\nThe master.R script doesn’t do a great deal, it loads libraries and then as the comments show, and its important to get into the habit of putting comments in scripts to help other people, including your future self, it then sets the working directory. It does this in a reproducible manner by first asking the operating system what the current directory is using the getwd() command and then appends various directory paths, such as data and saving it in the data_dir variable, this in turn has csv appended to it and saved in the csv_dir which points to the nested directory where our data files live.\nYou should get in the habit of using relative directories so that the code runs on different computers/systems, if you had hard coded the path based on where you store the files on your computer the script won’t run on any other computer until someone changes that value, relative paths get around that limitation.\nAfter setting directories a number of scripts are called using the source() command and within it I just paste the name of the script onto the r_scripts variable which holds the path to the r/ directory. The clean.R script is first called, followed by the simulate_data.R and then the tidymodels.R."
  },
  {
    "objectID": "index.html#scriptscode---rclean.r",
    "href": "index.html#scriptscode---rclean.r",
    "title": "Reproducible Research in Practice",
    "section": "Scripts/code - r/clean.R",
    "text": "Scripts/code - r/clean.R\n## Filename : clean.R\n## Description : Load and clean raw data, saving as a .RData file for subsequent analyses.\n\n## Read the data and convert to tibble\ndf_raw &lt;- read_csv(paste(csv_dir, \"Thy3000_DATA_LABELS_Raw.csv\", sep = \"/\"))\ndf_raw &lt;- as_tibble(df_raw)\n## Rename columns using dplyr::rename()\ndf_raw &lt;- dplyr::rename(df_raw,\n  record_id = \"Record ID\",\n  data_access_group = \"Data Access Group\",\n  study_id = \"Study ID\",\n  date_referral = \"1.1 Date of referral\",\n  clinic_recruiting = \"1.2 Which clinic was the patient recruited from?\",\n  clinic_recruiting_other = \"If Other\",\n  date_clinic = \"1.3. The date the patient was seen in clinic\",\n  referral_source = \"1.4 Referral source\",\n  referral_source_other = \"If Other, please specify\",\n  two_week_wait_referral = \"1.4.1 If GP, was it 2-week wait referral?\",\n  presentation = \"1.5. Presentation\",\n  presentation_complete = \"Complete?...12\",\n  age = \"2.1. Age of the patient when seen in clinic\",\n  bmi = \"2.2. Body Mass Index of patient\",\n  smoking_status = \"2.3. Smoking status\",\n  ...\n  )\n\nIts important to script the work you do on the code, it provides evidence of the changes that have been made to clean the code up and allows the work to be fully reproducible. Such an audit trail is useful as it allows mistakes to be corrected. This and other R and Quarto Markdown files are version controlled using Git which I’ll come onto shortly.\nThis script, r/clean.R does the hard work of cleaning/tidying the data.\nIt loads the data in and then renames a bunch of variables because spaces in names are a pain and all the numerical prefixes are pointless."
  },
  {
    "objectID": "index.html#scriptscode---rclean.r-cont.",
    "href": "index.html#scriptscode---rclean.r-cont.",
    "title": "Reproducible Research in Practice",
    "section": "Scripts/code - r/clean.R (cont.)",
    "text": "Scripts/code - r/clean.R (cont.)\n\n## Convert dates to elapsed dates using lubridate\ndf &lt;- df |&gt;\n  mutate(\n    date_referral = lubridate::dmy(date_referral),\n    date_clinic = lubridate::dmy(date_clinic),\n    date_initial_management_decision = lubridate::dmy(date_initial_management_decision),\n    date_treatment = lubridate::dmy(date_treatment),\n    routine_review_date_last_seen = lubridate::dmy(routine_review_date_last_seen)\n  )\n\n## Convert variables that are meant to be numeric but aren't\ndf &lt;- df |&gt;\n  dplyr::mutate(\n    bmi = as.numeric(bmi),\n  )\n\nTidyverse\n\n{dplyr}\n{lubridate}\nR for DataScience (2e)\n\n\n\nAnother important step to working with data is to ensure the dates are correct and recognised by the software, the strings people typically enter these as are not something that computers can do calculations on, instead software uses elapsed times and takes as epoch time which is the number seconds that have elapsed from midnight on 1970-01-01 and so internally these are stored as numeric values but they can be represented as human readable dates. But the advantage of having them stored as epoch time is that you can then perform calculations on them and work out periods of time.\nOften unless data capture has been done very carefully there will be errors in numerical variables such as including characters which means the whole column for something that is meant to be numeric such as Body Mass Index (bmi) are not the correct type, they’re strings rather than actual numbers. We can use the as.numeric() function here with the Tidyverse package dplyr::mutate() to replace these.\nIts worth mentioning the Tidyverse which is an “opinionated collection of R packages for data science” that make working with data in R considerably easier than the base functions. I would highly recommend the book.\nPerhaps the biggest and best feature of the Tidyverse is the pipe, here I’m using the base pipe |&gt; which allows commands to be written in a Western-style of grammar, reading from left to right and top down rather than in base R where you would nest functions within each other.\nThis vastly improves the readability of the code."
  },
  {
    "objectID": "index.html#scriptscode---rclean.r-cont.-1",
    "href": "index.html#scriptscode---rclean.r-cont.-1",
    "title": "Reproducible Research in Practice",
    "section": "Scripts/code - r/clean.R (cont.)",
    "text": "Scripts/code - r/clean.R (cont.)\n\ncheck_cols &lt;- c(\n  \"previous_neck_irradiation\",\n  \"incidental_imaging\",\n  \"retrosternal\",\n  \"palpable_lymphadenopathy\",\n  \"nodule_rapid_growth\",\n  \"thyroid_function_3months\",\n  \"ultrasound\",\n  \"elastography\",\n  \"ct_neck\",\n  \"mri_neck\",\n  \"iodine_scan\",\n  \"nodule_fna\",\n  \"core_biopsy\",\n  \"routine_review_ultrasound\",\n  \"routine_review_fna\",\n  \"routine_review_patient_signposting_information\"\n)\ndf &lt;- df %&gt;%\n  dplyr::mutate(across(\n    all_of(check_cols),\n    ~ dplyr::recode(.x,\n      \"Yes\" = 1,\n      \"No\" = 0,\n      \"Not Known\" = NA_real_\n    )\n  ))\n\nthyroid-cancer-prediction/r/clean.R\n\n\nAnother common task in cleaning data is to convert string variables such as Yes / No / Not Known to numerical binary variables. Typically there will be lots of columns on which you want to do this and rather than write the same code out lots there are a lot of neat ways of repeating commands across a range of variables.\nHere we save all the variables we want to convert in the check_cols variable and then within the dplyr::mutate() function we apply the same function dplyr::recode() across() all_of() this list, replacing Yes with 1, No with 0 and Not Known with R’s internal NA value.\nCurrently it has 704 lines so I can’t tal you through all of it but because this is all open if you want to look at the code you can do and I’ve included the link on this slide."
  },
  {
    "objectID": "index.html#scriptscode---rclean.r-cont.-2",
    "href": "index.html#scriptscode---rclean.r-cont.-2",
    "title": "Reproducible Research in Practice",
    "section": "Scripts/code - r/clean.R (cont.)",
    "text": "Scripts/code - r/clean.R (cont.)\n## Finally save the data\nsaveRDS(df, file = paste(r_dir, \"clean.rds\", sep = \"/\"))\n\nthyroid-cancer-prediction/r/clean.R\n\n\nFinally though we save the df data frame in the r_dir directory that was defined in the master.R script.\nI can re-run this at any time if for example there was an error in my code, or more patients have been collected and the dataset needs analysing again or conversely if someone withdraws from the study I could add lines to r/clean.R to remove them from the dataset that is being analysed."
  },
  {
    "objectID": "index.html#version-control",
    "href": "index.html#version-control",
    "title": "Reproducible Research in Practice",
    "section": "Version Control",
    "text": "Version Control\n\nKeep fine-grained records of changes to code.\nRegular saves of work.\nBackup and collaboration via GitHub / GitLab\nOrganised and consistent system, avoids…\n\n\nI’ve mentioned that the files for this work are version controlled, hands up anyone who has heared of Version Control?\nKeep your hands up if you’ve used version control?\nOk, thank you.\nVersion control has been around for a long time, you may be familiar with editions of books as one example or with Wikipedia where the changes and edits that people make are tracked"
  },
  {
    "objectID": "index.html#version-control-1",
    "href": "index.html#version-control-1",
    "title": "Reproducible Research in Practice",
    "section": "Version Control",
    "text": "Version Control"
  },
  {
    "objectID": "index.html#version-control-2",
    "href": "index.html#version-control-2",
    "title": "Reproducible Research in Practice",
    "section": "Version Control",
    "text": "Version Control\nTwo repositories on GitHub\n\nns-rse/thyroid-cancer-prediction - repository I started to show colleague how to use Git and R.\nmdp21oe/multicenter-thyroid - repository by Ovie to re-write his paper in Quarto Markdown."
  },
  {
    "objectID": "index.html#quarto-data-science-learning-community",
    "href": "index.html#quarto-data-science-learning-community",
    "title": "Reproducible Research in Practice",
    "section": "Quarto & Data Science Learning Community",
    "text": "Quarto & Data Science Learning Community\n\n\nThe official documentation is really good.\n\nGet Started\nMarkdown Basics\nGuide with many sections on Presentations Website, Books and more.\n\n\n\n\n    \nData Science Learning Community (dslc.io)\n\n\n\nI think most of the course material you’re learning is focused on RMarkdown but everything you learn can be applied to Quarto which is really the next iteration or generation of RMarkdown. If you’re keen to give it a try then the documentation is really good.\nPerhaps also of interest when you have questions about things which aren’t working as you’d expect or how to do something is the execellent Data Science Learning Community (dslc.io) (need R4DS community) which is a great place to join book clubs to work through things like R for Data Science (2e) and over 50 books clubs or ask questions in their Slack channel."
  },
  {
    "objectID": "index.html#sheffieldr-user-group",
    "href": "index.html#sheffieldr-user-group",
    "title": "Reproducible Research in Practice",
    "section": "SheffieldR User Group",
    "text": "SheffieldR User Group\n\n\n\n\n\nsheffieldr.github.io\n\n\n\n\n\n    \nsheffieldr.github.io\n\n\n\nIf you’re interested in learning more about the many wonderful things you can do with R then you might be interested in the SheffieldR User Group that meets roughly every month with presentations and talks on different packages and how to do different things with R.\nIts meant to be diverse, friendly and welcoming to users of all abilities.\n\n\n\n\nSlides : ns-rse.github.io/reproducible_research_example\n\n\n\n\n\n\n\n \n\n\nReproducible Research in Practice"
  }
]