[
  {
    "objectID": "index.html#scan-this",
    "href": "index.html#scan-this",
    "title": "Reproducible Research in Practice",
    "section": "Scan This",
    "text": "Scan This\n\n\n    \nns-rse.github.io/reproducible_research_example"
  },
  {
    "objectID": "index.html#who-am-iwhat-do-i-do",
    "href": "index.html#who-am-iwhat-do-i-do",
    "title": "Reproducible Research in Practice",
    "section": "Who Am I/What Do I Do?",
    "text": "Who Am I/What Do I Do?\n\n\n\nBackground in evolutionary and statistical genetics.\nGenetic Statistician\nMedical Statistician\nData Scientist\nğŸ‰ Research Software Engineer ğŸ‰\n\n\n\nLinux, R, Python, Bash\nLiterate Programming\nReproducible Research\nOpen Research\nFree Open Source Software\n\n\n\n\nBefore we get into the details I thought it might be useful to explain who am I am and why Iâ€™m here to talk to you today.\nI started my academic career studying Zoology and Genetics at Undergraduate then moved onto a Masters in Genetic Epidemiology, both here at the University of Sheffield quite a few years ago. After graduating I spent about eight or nine years as a Genetic Statistician trying to work out what genes are involved in complex diseases at various Universities, Manchester, Western Australia and then returning to Sheffield. I then shifted careers to work as a Medical Statistician for about nine years followed by four years in industry as a Data Scientist where I didnâ€™t actually do much data science but did learn a lot about software development which is how Iâ€™ve ended up back at the University of Sheffield as a Research Software Engineer.\nA common theme from my Masters on-wards is that I have used computers to write programmes and analyse data. Iâ€™ve taught myself Linux system administration and from a rudimentary training on Fortran, C and Stata have gone on to learn Bash, R and Python as well as a few other bits and pieces of different languages.\nVery early on in my career I developed an interest in literate programming and reproducible research which is why Aneta has invited me her today to talk to you and Iâ€™ll expand on these topics and show you some work Iâ€™m currently engaged in and how I undertake it in a reproducible manner.\nReproducible Research is one of the foundational aspects of Open Research as by ensuring our work is reproducible and open to review it improves confidence in its accuracy and reliability."
  },
  {
    "objectID": "index.html#reproducible-research",
    "href": "index.html#reproducible-research",
    "title": "Reproducible Research in Practice",
    "section": "Reproducible Research",
    "text": "Reproducible Research\n\nReproducibility is fundamental to the scientific method.\nTraditionally hand-written notebooks with methods shared in publications.\nModern equivalent is codeâ€¦\n\nSoftware\nStatistical scripts\n\nData cleaning\nAnalysis, graphs & tables\nNumbers and statistics"
  },
  {
    "objectID": "index.html#literate-programming---origins",
    "href": "index.html#literate-programming---origins",
    "title": "Reproducible Research in Practice",
    "section": "Literate Programming - Origins",
    "text": "Literate Programming - Origins\n\n\n\na computer program is given as an explanation of how it works in a natural language, such as English, interspersed (embedded) with snippets of macros and traditional source code, from which compilable source code can be generated.1\n\n\n\n\n\nLiterate Programming - Donald Knuth\n\n\n\n\n\nRMarkdown and other languages like it such as the newer Quarto and Emacsâ€™ Org-mode are literate programming languages which may be an unfamiliar term so Iâ€™ve borrowed the definition from Wikipedia.\nThe idea was originally proposed and developed the computer scientist Donald Knuth, and he literally wrote the book on it.\n\nWikipedia - Literate programming"
  },
  {
    "objectID": "index.html#literate-programming---better-programmes",
    "href": "index.html#literate-programming---better-programmes",
    "title": "Reproducible Research in Practice",
    "section": "Literate Programming - Better Programmes",
    "text": "Literate Programming - Better Programmes\n\n\n\nMy programs are not only explained better than ever before; they also are better programs, because the new methodology encourages me to do a better job.1\n\n\n\n\n\nLiterate Programming - Donald Knuth\n\n\n\n\n\nWhilst originating in computer science the principle has seen widespread adoption in research and data science because it encourages reproducible research and facilitates open access to research.\nAlso, as Knuth found when he adopted the practice it improved the quality of the programmes he wrote, and Iâ€™ve found the same is true when writing documents myself since adopting the practice over 20 years ago.\n\nKnuth (1984)"
  },
  {
    "objectID": "index.html#whats-involved",
    "href": "index.html#whats-involved",
    "title": "Reproducible Research in Practice",
    "section": "Whatâ€™s Involved?",
    "text": "Whatâ€™s Involved?\n\nLogical, ordered directory structure.\nScripts/code.\nVersion control of code.\nReproducible environment (R packages using renv).\n\n\nIt can seem overwhelming learning a new paradigm or framework for undertaking work and Iâ€™ve often found that people want to get on and do the work rather than take a step back and assess how they are going about it but its well worth taking the time out to review and assess your working practices and see how they can be improved.\nIâ€™m going to walk you through a project that Iâ€™ve been working on that is looking to improve the prediction of Thyroid Cancer. Its not my own work, its the topic for a PhD for a clinicial Dr Ovie Edafe who is a specialist in neck cancers and related surgery.\nThere are four broad areas that Iâ€™ll cover that hopefully align with the content you have already covered and will be covering in the coming weeks.\nThe first step is having an organised structure to your directories having data organised in a consistent and structured manner makes it considerably easier to work with.\nYou then need to write code or scripts, which are still code, that defines the steps you undertake in cleaning and tidying your data and getting it ready for analysis before another series of scripts are used to run the analysis.\nAll of the code that is written should be version controlled which allos you to track the history of the code and see what changes have been made over time. If a mistake is made it is possible to revert back to a previous state where things did work. Version control and tools such as Git and GitHub make it much easier to collaborate with others on research too.\nOne final step is having a reproducible environment under which your work is undertaken. This means the specific versions of packages that you have used for analysis should be recorded and used again in the future. In R this can be done via the renv package. Its not without problems but the situation today is far better than it used to be."
  },
  {
    "objectID": "index.html#directory-structure",
    "href": "index.html#directory-structure",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure",
    "text": "Directory Structure\n\nImportant to keep a copy of the raw data as received.\nData always needs cleaning.\n~80% of data analysis is data cleaning/wrangling data!\nAlways keep a record of changes you make to the data.\nSeparate directories for different data types and script/markdown files.\n\n\nWhen undertaking research its imperative to keep a copy of the raw data as received. This might be data from sensors that have captured data and if you work with this sort of data then its likely to be fairly well structured, but can also be the results of surveys that have been captured and stored in databases and then exported for you to work with. Depending on how well the data capture was setup you will almost invariably have to clean your data, in my experience about 80% of data analysis is cleaning the data and wrangling it such as deriving variables like age from date of birth, and on that note if you ever do want to analyse age as a variable try and capture date of birth as you can easily derive the age in years or categorise it into bins, but if you only ask people to say what age band they are in you canâ€™t go back the other way. Common errors in data cleaning are having string characters in variables that are meant to be numeric, or having categorical variables where people havenâ€™t entered the correct field and so you have to then work out how to tidy this which Iâ€™ll come on to.\nThe key thin is that its important to keep a record of the changes you make and these will be in R scripts or Markdown/Quarto files. And it therefore makes sense to separate your data from your scripts."
  },
  {
    "objectID": "index.html#directory-structure---thyroid-cancer-prediction",
    "href": "index.html#directory-structure---thyroid-cancer-prediction",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - Thyroid Cancer Prediction",
    "text": "Directory Structure - Thyroid Cancer Prediction\n\n\nâ± tree -d -L 2\n[4.0K Mar 19 12:36]  .\nâ”œâ”€â”€ [4.0K Nov 22 14:57]  ./data\nâ”‚Â Â  â”œâ”€â”€ [4.0K Jan  9 13:32]  ./data/csv\nâ”‚Â Â  â””â”€â”€ [4.0K Feb 29 17:27]  ./data/r\nâ”œâ”€â”€ [4.0K Mar 14 17:36]  ./docs\nâ”‚Â Â  â”œâ”€â”€ [   7 Jan  5 14:45]  ./docs/data -&gt; ../data\nâ”‚Â Â  â”œâ”€â”€ [4.0K Feb 29 15:38]  ./docs/modelling_cache\nâ”‚Â Â  â”œâ”€â”€ [4.0K Mar 14 17:21]  ./docs/modelling_files\nâ”‚Â Â  â”œâ”€â”€ [   4 Jan  5 14:44]  ./docs/r -&gt; ../r\nâ”‚Â Â  â””â”€â”€ [4.0K Mar 14 17:21]  ./docs/_site\nâ”œâ”€â”€ [4.0K Oct 19 11:40]  ./inst\nâ”œâ”€â”€ [4.0K Nov 16 10:54]  ./log\nâ”œâ”€â”€ [4.0K Oct 19 11:24]  ./node_modules\nâ”œâ”€â”€ [4.0K Oct 19 12:39]  ./pages\nâ”œâ”€â”€ [4.0K Oct 12 10:43]  ./papers\nâ”œâ”€â”€ [4.0K Nov  9 11:44]  ./quarto\nâ”‚Â Â  â””â”€â”€ [4.0K Oct 19 13:12]  ./quarto/_site\nâ”œâ”€â”€ [4.0K Mar 14 16:59]  ./r\nâ”œâ”€â”€ [4.0K Mar 14 17:28]  ./renv\nâ”‚Â Â  â”œâ”€â”€ [4.0K Nov 16 10:57]  ./renv/library\nâ”‚Â Â  â””â”€â”€ [4.0K Feb 29 14:28]  ./renv/staging\nâ”œâ”€â”€ [4.0K Jan 31 11:00]  ./_site\nâ”‚Â Â  â”œâ”€â”€ [4.0K Dec 19 16:36]  ./_site/data_files\nâ”‚Â Â  â”œâ”€â”€ [4.0K Feb 15 15:15]  ./_site/docs\nâ”‚Â Â  â”œâ”€â”€ [4.0K Dec 19 16:36]  ./_site/modelling_files\nâ”‚Â Â  â””â”€â”€ [4.0K Jan 25 17:22]  ./_site/site_libs\nâ””â”€â”€ [4.0K Feb  1 17:47]  ./tmp\n\n29 directories\n\nKey top-level directories\n\ndata/ - holds data.\n\ndata/csv - holds ASCII text CSV files.\ndata/r - holds .RData files.\n\ndocs/ - my Quarto files.\nr/ - my R-scripts.\n\n\n\n\nHere is an example of the directory structure of one of the repositories I have setup for this work.\nThe output only shows the nesting two directory levels deep but you can see that at the top level I have a number of directories, not all of them are relevant, but the key ones are listed on the right, there is the data/ directory which will hold all of the data, there are two sub-directories csv for raw CSV files and r which holds cleaned data in Râ€™s byte format which speeds up loading and preserves all the labelling and categorical variables.\nThe docs/ directory contains my Quarto source files that I write, both Quarto and RMarkdown will make a bunch of other directories when they are rendering your pages which are some of those listed such as _site but you donâ€™t need to worry about those.\nThe final key directory that I have is r/ which holds the R scripts that I write."
  },
  {
    "objectID": "index.html#directory-structure---data",
    "href": "index.html#directory-structure---data",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - data/",
    "text": "Directory Structure - data/\n\n\nâ± tree data\n[4.0K Nov 22 14:57]  data\nâ”œâ”€â”€ [4.0K Jan  9 13:32]  data/csv\nâ”‚Â Â  â”œâ”€â”€ [ 20K Jan  9 13:31]  data/csv/sheffield_thyroid_nodule.csv\nâ”‚Â Â  â””â”€â”€ [393K Nov  2 11:08]  data/csv/Thy3000_DATA_LABELS_Raw.csv\nâ””â”€â”€ [4.0K Feb 29 17:27]  data/r\n    â”œâ”€â”€ [ 30K Mar 14 11:12]  data/r/clean.rds\n    â”œâ”€â”€ [136K Feb 29 17:56]  data/r/elastic_net.RData\n    â”œâ”€â”€ [136K Feb 29 17:56]  data/r/lasso.RData\n    â”œâ”€â”€ [129K Feb 29 17:56]  data/r/rf.RData\n    â”œâ”€â”€ [137K Feb 29 17:58]  data/r/svm.RData\n    â””â”€â”€ [ 14K Feb 29 17:56]  data/r/xgboost.RData\n\n3 directories, 9 files\n\nFiles\n\ndata/csv/\n\ndata/csv/sheffield_thyroid_nodule.csv - Data!\ndata/csv/Thy3000_DATA_LABELS_Raw.csv - Data Dictionary.\n\ndata/r/ - .\n\ndata/r/clean.rds - Clean data set.\ndata/r/elastic_net.RData - Elastic Net model.\ndata/r/lasso.RData - LASSO model.\ndata/r/rf.RData - Random Forest model.\ndata/r/svm.RData - SVM model.\ndata/r/xgboost.RData = XGBoost model\n\n\n\n\n\nThe data/csv directory holds the raw data and there are two files the raw data sheffield_thyroid_nodule.csv and the data dictionary Thy3000_DATA_LABELS_Raw.csv.\nThe data/r directory holds the cleaned data in clean.rds and the results of fitting various different types of models to the data."
  },
  {
    "objectID": "index.html#directory-structure---data-1",
    "href": "index.html#directory-structure---data-1",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - data/",
    "text": "Directory Structure - data/\n\n\nâ± tree data\n[4.0K Nov 22 14:57]  data\nâ”œâ”€â”€ [4.0K Jan  9 13:32]  data/csv\nâ”‚Â Â  â”œâ”€â”€ [ 20K Jan  9 13:31]  data/csv/sheffield_thyroid_nodule.csv\nâ”‚Â Â  â””â”€â”€ [393K Nov  2 11:08]  data/csv/Thy3000_DATA_LABELS_Raw.csv\nâ””â”€â”€ [4.0K Feb 29 17:27]  data/r\n    â”œâ”€â”€ [ 30K Mar 14 11:12]  data/r/clean.rds\n    â”œâ”€â”€ [136K Feb 29 17:56]  data/r/elastic_net.RData\n    â”œâ”€â”€ [136K Feb 29 17:56]  data/r/lasso.RData\n    â”œâ”€â”€ [129K Feb 29 17:56]  data/r/rf.RData\n    â”œâ”€â”€ [137K Feb 29 17:58]  data/r/svm.RData\n    â””â”€â”€ [ 14K Feb 29 17:56]  data/r/xgboost.RData\n\n3 directories, 9 files\n\nFiles\n\ndata/csv/\n\ndata/csv/sheffield_thyroid_nodule.csv - Data!\ndata/csv/Thy3000_DATA_LABELS_Raw.csv - Data Dictionary.\n\ndata/r/ - .\n\ndata/r/clean.rds - Clean data set.\ndata/r/elastic_net.RData - Elastic Net model.\ndata/r/lasso.RData - LASSO model.\ndata/r/rf.RData - Random Forest model.\ndata/r/svm.RData - SVM model.\ndata/r/xgboost.RData = XGBoost model\n\n\n\n\n\nThe data/csv directory holds the raw data and there are two files the raw data sheffield_thyroid_nodule.csv and the data dictionary Thy3000_DATA_LABELS_Raw.csv.\nThe data/r directory holds the cleaned data in clean.rds and the results of fitting various different types of models to the data."
  },
  {
    "objectID": "index.html#directory-structure---docs",
    "href": "index.html#directory-structure---docs",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - docs/",
    "text": "Directory Structure - docs/\nâ± l docs | grep -v \"~\"\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 17:36:04 2024 .\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 28 16:35:45 2024 ..\n.rw-r--r-- neil neil  10 B  Thu Feb 15 15:16:48 2024 .gitignore\n.rw-r--r-- neil neil  12 KB Thu Jan 25 15:35:49 2024 .modelling.qmd\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 17:15:43 2024 .quarto\n.rw-r--r-- neil neil 483 B  Thu Mar 14 16:59:28 2024 _quarto.yml\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 17:21:20 2024 _site\n.rw-r--r-- neil neil 408 B  Thu Mar 14 16:57:10 2024 about.qmd\n.rw-r--r-- neil neil 1.2 KB Thu Mar 14 16:57:10 2024 citations.qmd\nlrwxrwxrwx neil neil   7 B  Fri Jan  5 14:45:10 2024 data â‡’ ../data\n.rw-r--r-- neil neil  33 KB Thu Mar 14 16:57:10 2024 data.qmd\n.rw-r--r-- neil neil 363 B  Thu Mar 14 16:57:10 2024 index.qmd\n.rw-r--r-- neil neil 569 B  Thu Mar 14 16:57:10 2024 links.qmd\n.rw-r--r-- neil neil 2.0 KB Thu Mar 14 16:57:10 2024 literature.qmd\n.rw-r--r-- neil neil  32 KB Thu Mar 14 17:36:04 2024 modelling.qmd\ndrwxr-xr-x neil neil 4.0 KB Thu Feb 29 15:38:53 2024 modelling_cache\n.rw-r--r-- neil neil 3.5 KB Thu Mar 14 17:31:46 2024 modelling_elastic_net.qmd\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 17:21:18 2024 modelling_files\n.rw-r--r-- neil neil 5.4 KB Thu Mar 14 17:31:46 2024 modelling_lasso.qmd\n.rw-r--r-- neil neil 3.6 KB Thu Mar 14 17:31:46 2024 modelling_random_forest.qmd\n.rw-r--r-- neil neil 7.0 KB Thu Mar 14 17:31:46 2024 modelling_tidymodel.qmd\nlrwxrwxrwx neil neil   4 B  Fri Jan  5 14:44:09 2024 r â‡’ ../r\n.rw-r--r-- neil neil  18 KB Thu Mar 14 16:57:10 2024 references.bib\n.rw-r--r-- neil neil 2.7 KB Thu Mar 14 16:57:10 2024 reproducibility.qmd\n.rw-r--r-- neil neil  17 B  Thu Mar 14 16:59:28 2024 styles.css\n\nThe docs/ directory holds my Quarto files which all end in .qmd. I donâ€™t like having large files to navigate so split my code and papers into a number of smaller files that do specific things and include these from the master document which is index.qmd. There is a references.bib file which contains citations so we can include citations easily. The _quarto.yml files is a key file which defines how the Quarto project is setup and rendered but I wonâ€™t cover that in detail here."
  },
  {
    "objectID": "index.html#directory-structure---r",
    "href": "index.html#directory-structure---r",
    "title": "Reproducible Research in Practice",
    "section": "Directory Structure - r/",
    "text": "Directory Structure - r/\nâ± l r | grep -v \"~\"\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 14 16:59:28 2024 .\ndrwxr-xr-x neil neil 4.0 KB Thu Mar 28 16:35:45 2024 ..\n.rw-r--r-- neil neil  28 KB Thu Mar 14 16:56:18 2024 clean.R\n.rw-r--r-- neil neil 684 B  Thu Mar 14 16:59:28 2024 master.R\n.rw-r--r-- neil neil  15 KB Thu Feb 29 14:40:13 2024 modelling.R\n.rw-r--r-- neil neil 2.6 KB Thu Mar 14 16:59:28 2024 simulate_data.R\n.rw-r--r-- neil neil 233 B  Thu Jan 25 17:02:10 2024 summary.R\n.rw-r--r-- neil neil 2.9 KB Thu Mar 14 16:57:10 2024 tidymodel.R\n\nThe r/ directory holds my R scripts, the key one is master.R which holds the main commands that setup the R environment, load libraries and set relative directories. The clean.R file does what it says on the tin, it cleans the raw data and saves it in R format. There are then scripts for modelling and simulating data.\nNow that weâ€™ve covered how I organise my data we can start looking at some code, but before I move on are there any questions about this aspect?"
  },
  {
    "objectID": "index.html#scriptscode---master.r",
    "href": "index.html#scriptscode---master.r",
    "title": "Reproducible Research in Practice",
    "section": "Scripts/Code - master.R",
    "text": "Scripts/Code - master.R\n## Filename    : master.R\n## Description : Master file that controls running of all subsequent scripts.\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(Hmisc)\nlibrary(lubridate)\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(vip)\n\n## Set directories based on current location\nbase_dir &lt;- getwd()\ndata_dir &lt;- paste(base_dir, \"data\", sep = \"/\")\ncsv_dir &lt;- paste(data_dir, \"csv\", sep = \"/\")\nr_dir &lt;- paste(data_dir, \"r\", sep = \"/\")\nr_scripts &lt;- paste(base_dir, \"r\", sep = \"/\")\n\n## Clean the data\nsource(paste(r_scripts, \"clean.R\", sep = \"/\"))\n\n\n## Simulate data\nsource(paste(r_scripts, \"simulate_data.R\", sep = \"/\"))\n\n## Run Statistical models\nsource(paste(r_scripts, \"tidymodel.R\", sep = \"/\"))\n\nThe master.R script doesnâ€™t do a great deal, it loads libraries and then as the comments show, and its important to get into the habit of putting comments in scripts to help other people, including your future self, it then sets the working directory. It does this in a reproducible manner by first asking the operating system what the current directory is using the getwd() command and then appends various directory paths, such as data and saving it in the data_dir variable, this in turn has csv appended to it and saved in the csv_dir which points to the nested directory where our data files live.\nYou should get in the habit of using relative directories so that the code runs on different computers/systems, if you had hard coded the path based on where you store the files on your computer the script wonâ€™t run on any other computer until someone changes that value, relative paths get around that limitation.\nAfter setting directories a number of scripts are called using the source() command and within it I just paste the name of the script onto the r_scripts variable which holds the path to the r/ directory. The clean.R script is first called, followed by the simulate_data.R and then the tidymodels.R."
  },
  {
    "objectID": "index.html#version-control",
    "href": "index.html#version-control",
    "title": "Reproducible Research in Practice",
    "section": "Version Control",
    "text": "Version Control\nTwo repositories on GitHub\n\nns-rse/thyroid-cancer-prediction - repository I started to show colleague how to use Git and R.\nmdp21oe/multicenter-thyroid - repository by Ovie to re-write his paper in Quarto Markdown.\n\n\n\n\n\nSlides : ns-rse.github.io/reproducible_research_example\n\n\n\n\n\n\n\n \n\n\nReproducible Research in Practice"
  }
]